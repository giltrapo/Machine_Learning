---
title: "Machine_learning_project"
author: "Jose Ignacio GÃ³mez Marcelo"
date: "30 July 2017"
output:
  html_document:
    keep_md: true
---

## Overview
This paper is the result of the Coursera Machine Learning course project and explains the steps that have been taken to adjust a classification model that allows predicting the quality of execution of weight lifting exercises.

The objective is to predict, based on information about the movements performed during weight lifting exercises, that were collected with wereables devices, whether the exercise is being performed correctly (class A) or not (classes B, C, D and E)


## Software
This data analysis was carried out using R, a free software environment for statistical computing and graphics.
```{r sessioninfo}
sessionInfo()
```
Additionally, the packages `lattice`, `ggplot2`, `caret`, `foreach`, `randomForest`, `gbm`, `parallel`, `Iterators`, `doParallel`, `cowplot` and `gridExtra` were used.

```{r libraries}
library(lattice)
library(ggplot2)
library(caret)
library(foreach)
library(randomForest)
library(gbm)
library(parallel)
library(iterators)
library(doParallel)
library(cowplot)
library(gridExtra)
```

## Exploratory Analysis and cleaning
First we download the training and testing datasets.

```{r downloadatasets}
train_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
test_url <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
training <- read.csv(train_url)
testing <- read.csv(test_url)
```

Let's take a look at the training dataset.

```{r datasetstr}
dim(training)
```

We have 19622 observations and 160 variables. Let's see the structure of dataset.

```{r datasetstr}
str(training)
```

There are a lot of numeric variables coded like factors. Let's
convert all dependent variables to numeric.

```{r convert_factors_to_numeric, warning = FALSE}
training[,-c(1:7,160)] <- lapply(training[,-c(1:7,160)], function(x) as.numeric(as.character(x)))
```

It seems that the dataset has many missing values (NAs). Let's check it.

```{r check_NAs}
table(round(sapply(training[,-c(1:7,160)], function(x) sum(is.na(x))/length(x)), 2))
```

There are 94 variables with approximately 98% of missing values (NAs) and 6 variables that have 100%, that is, they have no information.

According to the terminology that Rubin coined to describe the different mechanisms of missing values, it seems that this is a case of Missing Completely at Random (MCAR). It means that the probability that an observation is missing is unrelated to the value of this observation or to the value of any other variables. Perhaps the Razor Inertial Measurement units (IMUs) used to record participants' movements had a problem with some specific movement. Hence the consistency in the frequency of values lost in some of the variables.

Regardless of the method we are going to use to build a classifier, the proportion of missing values is too high to attempt any method of imputation, so we will eliminate those variables with more than 95% of missing values from the analysis.

We will also eliminate the variables referred to the time windows used to record data, since, at first glance, they do not seem to be relevant as predictors. We will also eliminate the variable that identifies the user, since we want that the classifier model can identify the quality of the exercise performed, regardless of the characteristics of a specific individual.

```{r select_features}
feat_sec <- names(training[,-c(1:7,160)])[sapply(training[,-c(1:7,160)], function(x) sum(is.na(x))/length(x)) < 0.9]
training <- training[, c(feat_sec, "classe")]
```

After this elimination process we have 52 predictor variables. Let's see if they all have enough variability.

```{r nearzero_select}
nearZeroVar(training, saveMetrics = TRUE)
```

There is no near zero variables, so we can construct the model with these dataset.

Since we are going to use non-parametric models for the construction of our classifier, we will not test variables' skewness nor will we perform any transformation in them, such as centering and scaling them.

## Classifiers building

In order to test our classifier on a new dataset, before applying it to `testing` dataset, we will split the `training` file into two parts: 90% will be used to train the models (`trainset`), and the remaining 10% to test them (`validset`).

```{r splitting_dataset}
set.seed(42)
train_index <- createDataPartition(y = training$classe, p = .9, list = FALSE)
trainset <- training[train_index,]
validset <- training[-train_index,]
x <- trainset[,-53]
y <- trainset[, 53]
```

### Random Forest

First we are going to train a model with Random Forest algorithm.

```{r randomforest_model}
cluster <- makeCluster(detectCores() - 1)
registerDoParallel(cluster)
trainfit <- trainControl(method = "cv", number = 5, allowParallel = TRUE)
set.seed(42)
rf_model <- train(x, y, method="rf", trControl = trainfit)
stopCluster(cluster)
registerDoSEQ()
```

Let's test with the `validset' and plot the output.

```{r rf_model_mat_conf}
rf_mat_conf <- confusionMatrix(predict(rf_model, validset), validset$classe)
```


```{r plot_matrix_function}
plot_mat_conf <- function(mat_conf, title) {
  confussion <- as.data.frame(mat_conf$table)
  confussion$categ <- ifelse(confussion$Freq > 100, "D", "R")
  confussion$categ <- as.factor(confussion$categ)
  myColors <- c("#3F97D0", "#F7AD50")
  names(myColors) <- levels(confussion$categ)
  colScale <- scale_colour_manual(name = "categ", values = myColors)
  
  # build plot confussion matrix
  p1 <- ggplot(confussion, aes(x = Reference, y = Prediction, colour = categ)) + geom_point(shape = 15, cex = 28, colour = "black", show.legend = FALSE) + geom_point(shape = 15, cex = 27, show.legend = FALSE) + scale_x_discrete(name = "Reference", position = "top") + scale_y_discrete(name = "Prediction", limits = rev(levels(confussion$Prediction))) + geom_text(aes(label = sprintf("%1.0f", Freq)), cex = 4, col = "white") + coord_fixed(ratio = 1) + colScale + theme_bw()
  
  # build plot overall results
  overall <- data.frame(t(round(mat_conf$overall, 4)))
  mytheme <- ttheme_default(core = list(fg_params = list(cex = 1.0)), colhead = list(fg_params = list(cex = 0.8)), rowhead = list(fg_params = list(cex = 0)))
  p2 <- tableGrob(overall, theme = mytheme)
  
  # join all
  p3 <- plot_grid(p1, p2, align = "v", ncol = 1, rel_heights = c(4, 1))
  
  # add title
  p4 <- ggdraw() + draw_label(title, fontface='bold')
  
  # plot all
  plot_grid(p4, p3, ncol = 1, rel_heights = c(0.1, 1))
  
}
```

```{r plot_rf_model_conf}
plot_conf_mat(rf_mat_conf, "Random Forest model")
```

The precision of the model is very good (0.9959). In the movements referred to the class A (exercise done correctly) the model obtains a 100% of hits.

### Stochastic Gradient Boosting with Trees 

Now we use `gbm` to build another classificator.

```{r boosting_model}
registerDoParallel(cluster)
set.seed(42)
gbm_model <- train(x, y, method="gbm", trControl = trainfit, verbose = FALSE)
stopCluster(cluster)
registerDoSEQ()
```

And we test in 'validset' too.

```{r gbm_model_mat_conf}
gbm_mat_conf <- confusionMatrix(predict(gbm_model, validset), validset$classe)
```

```{r plot_gbm_model_conf}
plot_conf_mat(gbm_conf_mat, "Stochastic Gradient Boosting model")
```

The precision of this model is also very good (0.9959), but it is somewhat lower than that obtained by Random Forest, so we will use this last model to predict the classes of the test dataset.


